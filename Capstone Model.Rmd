---
title: "Final Model"
author: "JVWCD Capstone Group"
date: "4/14/2022"
output: 
  html_document:
    highlight: breezedark
    number_sections: yes
    toc: yes
    fig_width: 15
    fig_height: 10
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Packages

```{r echo=T, results='hide', message=F, warning=F}
list.of.packages <- c("tidyverse",
                      "lubridate",
                      "chron",
                      "knitr",
                      "corrplot",
                      "caret",
                      "scales",
                      "gridExtra",
                      "useful",
                      "ISOweek",
                      "kableExtra",
                      "matrixStats",
                      "rminer",
                      "mltools",
                      "zoo",
                      "RWeka",
                      "kernlab")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
```


```{r}
library(tidyverse)
library(lubridate)
library(chron)
library(knitr)
library(corrplot)
library(caret)
library(scales)
library(gridExtra)
library(useful)
library(ISOweek)
library(kableExtra)
library(matrixStats)
library(rminer)
library(mltools)
library(zoo)
library(RWeka)
library(kernlab)

MLP <- make_Weka_classifier("weka/classifiers/functions/MultilayerPerceptron")

# R2
rsq <- function (x, y) cor(x, y) ^ 2
# Performance Metrics
metrics_list = c("R2","MAE","MAPE","RMSE")
```

# Read CSV files and pre process

```{r}
wa <- read.csv("new_weather_slc_airport.csv")%>%
  mutate(season = ifelse(CalendarMonth %in% c('3','4','5'), 'Spring',
                         ifelse(CalendarMonth %in% c('6','7','8'), 'Summer',
                                ifelse(CalendarMonth %in% c('9','10','11'), 'Fall',
                                       ifelse(CalendarMonth %in% c('12','1','2'), 'Winter','0')))),
         #RainDays = factor(RainDays),
         date = as.Date(WeatherDate,format="%m/%d/%Y"),
         RainDays = ifelse(Precipitation < 0.05, 0 , RainDays),
         Precipitation = ifelse(Precipitation < 0.05, 0 , Precipitation))%>%
  filter(CalendarYear>=2020)


sd <- read.csv("new_daily_demand.csv")%>%
  rename('avg_demand_cfs' = 'Avg.Daily.Demand..cfs.',
         'avg_demand_af' = 'Avg.Daily.Demand..af.',
         'avg_demand_mgd' = 'Avg.Daily.Demand..mgd.',
         'max_demand_cfs' = 'Max.Daily.Demand..cfs.',
         'max_demand_af' = 'Max.Daily.Demand..af.',
         'max_demand_mgd' = 'Max.Daily.Demand..mgd.',
         'min_demand_cfs' = 'Min.Daily.Demand..cfs.',
         'min_demand_af' = 'Min.Daily.Demand..af.',
         'min_demand_mgd' = 'Min.Daily.Demand..mgd.')%>%#Clifton said this is a min
  mutate(date = as.Date(ReadDate,format="%m/%d/%Y"))


wd <- merge(wa,sd,by="date")


mgd_avg <- wd%>%
  select(-avg_demand_cfs,
         -avg_demand_af,
         #-avg_demand_mgd, ## Target Variable
         -max_demand_cfs,
         -max_demand_af,
         -max_demand_mgd,
         -min_demand_cfs,
         -min_demand_af,
         -min_demand_mgd)%>%
  select(-WeatherDate,-ReadDate)


rainwk <- mgd_avg%>%
  mutate(Week_no = format(date, "%U"))%>%
  group_by(Week_no)%>%
  summarize(RainWeek = as.factor(ifelse(sum(RainDays)>0,1,0)))

mgd_avg <- mgd_avg %>%
  mutate(Week_no = as.factor(format(date, "%U")),
         RainDays = as.factor(RainDays),
         season = as.factor(season))

mgd_avg <- dplyr::left_join(mgd_avg,rainwk,by="Week_no")

mgd_avg <- mgd_avg%>% select(-Week_no)

# Rollmean 9 Day Average Calculations
Avg4 <- mgd_avg %>% 
  mutate(TempMean4Day = rollmean(TemperatureMean, k = 9, fill = mean(TemperatureMean)),
         Precip4Day = rollmean(Precipitation, k = 9, fill = mean(Precipitation)),
         SnowDepth4Day = rollmean(SnowDepth, k = 9, fill = mean(SnowDepth)))%>% 
  select(-Precipitation, -TemperatureMean, -SnowDepth)
```

# Data After Pre Processing

```{r}
summary(Avg4)
```

# Log Numeric Variables

```{r}
Avg4g <- Avg4%>%
  mutate(
         avg_demand_mgd = log(avg_demand_mgd),
         TemperatureMax = log(TemperatureMax),
         TemperatureMin = log(TemperatureMin),
         CoolingDegreeDays = ifelse(CoolingDegreeDays >= 1,
                                    log(CoolingDegreeDays),
                                    CoolingDegreeDays
         ),
         SnowFall = ifelse(SnowFall >= 0.01,
                                    log(SnowFall),
                                    SnowFall
         ),
         TempMean4Day = log(TempMean4Day),
         Precip4Day = ifelse(Precip4Day >= 0.01,
                                    log(Precip4Day),
                                    Precip4Day
         ),
         SnowDepth4Day = ifelse(SnowDepth4Day >= 0.01,
                                    log(SnowDepth4Day),
                                    SnowDepth4Day
         ),
         season = as.factor(season),
         CalendarMonth = as.factor(CalendarMonth)
         )%>%
  select(-date,
         -CalendarYear,
         #-CalendarMonth,
         -CalendarDay)
  

```

# Remove Calendar Variables from Datasets to see how model performance if affected.

```{r}
# Spring
Avg4_Sp <- Avg4%>% 
  filter(season == 'Spring')
# Summer
Avg4_Su <- Avg4%>% 
  filter(season == 'Summer')
# Fall
Avg4_F <- Avg4%>% 
  filter(season == 'Fall')
# Winter is coming
Avg4_W <- Avg4%>% 
  filter(season == 'Winter')

# Only 2022
Avg4_2022 <- Avg4%>% 
  filter(CalendarYear == 2022)

# Remove 2022
#Avg4 <- Avg4%>%
#  filter(CalendarYear != 2022)
```



```{r}
summary(Avg4)

```

# Split all datasets into Train and test

```{r}
set.seed(6496)

#Avg4

ti <- createDataPartition(Avg4$avg_demand_mgd, p=0.8,
                         list = FALSE)

train <- Avg4[ti,]
test <- Avg4[-ti,]
```

# Models

## lm Model

```{r}
mod1 <- lm(avg_demand_mgd ~ ., data=train)
```


# Model Selection

## Performance Metrics

R2 : Tells us that the predictor variables in the model are able to explain x% of the variation in target variable.

MAE: Is to subtract our predicted value and actual value at each time point to obtain the absolute value, and then average it out.

RMSE: tells us the average deviation between the predicted demand made by the model and the actual demand value.

MAPE: returns error as a percentage, making it easy to understand:
MAPE	Interpretation
' < 10 %	Very good
' 10 % - 20 %	Good
' 20 % - 50 %	OK
' > 50 %	Not good

# Model Performance

## LM

```{r}
# Train
trainpred <- mod1%>% 
  predict(train)

# Predictions with 95% CI
trainpredCI <- mod1 %>% 
  predict(train, interval = "confidence")


compare <- data.frame(actual = train$avg_demand_mgd,
                      predicted = trainpred)

error <- RMSE(trainpred,train$avg_demand_mgd)
ttarg<-train$avg_demand_mgd
print("Train")
mmetric(ttarg,trainpred,metrics_list)

print("_____________________________________")

# Test
predictions <- mod1%>% 
  predict(test)

# Predictions with 95% CI
testpredCI <- mod1 %>% 
  predict(test, interval = "confidence")

compare <- data.frame(actual = test$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,test$avg_demand_mgd)
targ<-test$avg_demand_mgd
print("Test")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# 2022
predictions <- mod1%>% 
  predict(Avg4_2022)

# Predictions with 95% CI
predictions2022CI <- mod1 %>% 
  predict(Avg4_2022, interval = "confidence")

compare <- data.frame(actual = Avg4_2022$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_2022$avg_demand_mgd)
targ<-Avg4_2022$avg_demand_mgd
print("2022")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# Spring
predictions <- mod1%>% 
  predict(Avg4_Sp)

# Predictions with 95% CI
predictions <- mod1%>% 
  predict(Avg4_Sp, interval = "confidence")

compare <- data.frame(actual = Avg4_Sp$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_Sp$avg_demand_mgd)
targ<-Avg4_Sp$avg_demand_mgd
print("Spring")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# Summer
predictions <- mod1%>% 
  predict(Avg4_Su)

# Predictions with 95% CI
predictions <- mod1%>% 
  predict(Avg4_Sy, interval = "confidence")


compare <- data.frame(actual = Avg4_Su$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_Su$avg_demand_mgd)
targ<-Avg4_Su$avg_demand_mgd
print("Summer")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# Fall
predictions <- mod1%>% 
  predict(Avg4_F)

# Predictions with 95% CI
predictions <- mod1%>% 
  predict(Avg4_F, interval = "confidence")


compare <- data.frame(actual = Avg4_F$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_F$avg_demand_mgd)
targ<-Avg4_F$avg_demand_mgd
print("Fall")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# Winter
predictions <- mod1%>% 
  predict(Avg4_W)

# Predictions with 95% CI
predictions <- mod1%>% 
  predict(Avg4_W, interval = "confidence")

compare <- data.frame(actual = Avg4_W$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_W$avg_demand_mgd)
targ<-Avg4_W$avg_demand_mgd
print("Winter is coming (House Stark)")
mmetric(targ,predictions,metrics_list)
```

## MLP Model

Multi-layer perceptron

```{r}
MLP <- make_Weka_classifier("weka/classifiers/functions/MultilayerPerceptron")
l <- 0.3
m <- 0.2
n <-100
h <- 'a'


mod2 <- MLP(avg_demand_mgd ~ ., data = train, control = Weka_control(L=l,M=m, N=n, H=h))
```

 -L <learning rate>
  Learning rate for the backpropagation algorithm.
  (Value should be between 0 - 1, Default = 0.3).
 
 -M <momentum>
  Momentum rate for the backpropagation algorithm.
  (Value should be between 0 - 1, Default = 0.2).
 
 -N <number of epochs>
  Number of epochs to train through.
  (Default = 500).

 -H <comma separated numbers for nodes on each layer>
  The hidden layers to be created for the network.
  a = (features + classes) / 2
  i = features
  o = classes
  t = features + classes.

https://weka.sourceforge.io/doc.dev/weka/classifiers/functions/MultilayerPerceptron.html


```{r}
# Train
trainpred <- mod2%>% 
  predict(train)

# Predictions with 95% CI
trainpredCI <- mod2 %>% 
  predict(train, interval = "confidence")

compare <- data.frame(actual = train$avg_demand_mgd,
                      predicted = trainpred)

error <- RMSE(trainpred,train$avg_demand_mgd)
ttarg<-train$avg_demand_mgd
print("Train")
mmetric(ttarg,trainpred,metrics_list)

print("_____________________________________")

# Test
predictions <- mod2%>% 
  predict(test)

# Predictions with 95% CI
testpredCI <- mod2 %>% 
  predict(test, interval = "confidence")

compare <- data.frame(actual = test$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,test$avg_demand_mgd)
targ<-test$avg_demand_mgd
print("Test")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# 2022
predictions <- mod2%>% 
  predict(Avg4_2022)

# Predictions with 95% CI
predictions <- mod2 %>% 
  predict(Avg4_2022, interval = "confidence")

compare <- data.frame(actual = Avg4_2022$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_2022$avg_demand_mgd)
targ<-Avg4_2022$avg_demand_mgd
print("2022")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# Spring
predictions <- mod2%>% 
  predict(Avg4_Sp)

# Predictions with 95% CI
predictions <- mod2 %>% 
  predict(Avg4_Sp, interval = "confidence")

compare <- data.frame(actual = Avg4_Sp$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_Sp$avg_demand_mgd)
targ<-Avg4_Sp$avg_demand_mgd
print("Spring")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# Summer
predictions <- mod2%>% 
  predict(Avg4_Su)

# Predictions with 95% CI
predictions <- mod2 %>% 
  predict(Avg4_Su, interval = "confidence")

compare <- data.frame(actual = Avg4_Su$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_Su$avg_demand_mgd)
targ<-Avg4_Su$avg_demand_mgd
print("Summer")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# Fall
predictions <- mod2%>% 
  predict(Avg4_F)

# Predictions with 95% CI
predictions <- mod2 %>% 
  predict(Avg4_F, interval = "confidence")

compare <- data.frame(actual = Avg4_F$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_F$avg_demand_mgd)
targ<-Avg4_F$avg_demand_mgd
print("Fall")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# Winter
predictions <- mod2%>% 
  predict(Avg4_W)

# Predictions with 95% CI
predictions <- mod2 %>% 
  predict(Avg4_W, interval = "confidence")

compare <- data.frame(actual = Avg4_W$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_W$avg_demand_mgd)
targ<-Avg4_W$avg_demand_mgd
print("Winter is coming (House Stark)")
mmetric(targ,predictions,metrics_list)
```


## knn Model

```{r}
mod3 <- IBk(avg_demand_mgd ~ ., data = train, control = Weka_control(K = 35, I= TRUE))
```

Valid options are:

 -I
  Weight neighbours by the inverse of their distance
  (use when k > 1)
 -F
  Weight neighbours by 1 - their distance
  (use when k > 1)
 -K <number of neighbors>
  Number of nearest neighbours (k) used in classification.
  (Default = 1)
 -E
  Minimise mean squared error rather than mean absolute
  error when using -X option with numeric prediction.
 -W <window size>
  Maximum number of training instances maintained.
  Training instances are dropped FIFO. (Default = no window)
 -X
  Select the number of nearest neighbours between 1
  and the k value specified using hold-one-out evaluation
  on the training data (use when k > 1)
 -A
  The nearest neighbour search algorithm to use (default: weka.core.neighboursearch.LinearNNSearch).


```{r}
# Train
trainpred <- mod3%>% 
  predict(train)

# Predictions with 95% CI
trainpredCI <- mod3 %>% 
  predict(train, interval = "confidence")

compare <- data.frame(actual = train$avg_demand_mgd,
                      predicted = trainpred)

error <- RMSE(trainpred,train$avg_demand_mgd)
ttarg<-train$avg_demand_mgd
print("Train")
mmetric(ttarg,trainpred,metrics_list)

print("_____________________________________")

# Test
predictions <- mod3%>% 
  predict(test)

# Predictions with 95% CI
testpredCI <- mod3 %>% 
  predict(test, interval = "confidence")

compare <- data.frame(actual = test$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,test$avg_demand_mgd)
targ<-test$avg_demand_mgd
print("Test")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# 2022
predictions <- mod3%>% 
  predict(Avg4_2022)

# Predictions with 95% CI
predictions <- mod3 %>% 
  predict(Avg4_2022, interval = "confidence")

compare <- data.frame(actual = Avg4_2022$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_2022$avg_demand_mgd)
targ<-Avg4_2022$avg_demand_mgd
print("2022")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# Spring
predictions <- mod3%>% 
  predict(Avg4_Sp)

# Predictions with 95% CI
predictions <- mod3 %>% 
  predict(Avg4_Sp, interval = "confidence")

compare <- data.frame(actual = Avg4_Sp$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_Sp$avg_demand_mgd)
targ<-Avg4_Sp$avg_demand_mgd
print("Spring")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# Summer
predictions <- mod3%>% 
  predict(Avg4_Su)

# Predictions with 95% CI
predictions <- mod3 %>% 
  predict(Avg4_Su, interval = "confidence")

compare <- data.frame(actual = Avg4_Su$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_Su$avg_demand_mgd)
targ<-Avg4_Su$avg_demand_mgd
print("Summer")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# Fall
predictions <- mod3%>% 
  predict(Avg4_F)

# Predictions with 95% CI
predictions <- mod3 %>% 
  predict(Avg4_F, interval = "confidence")

compare <- data.frame(actual = Avg4_F$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_F$avg_demand_mgd)
targ<-Avg4_F$avg_demand_mgd
print("Fall")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# Winter
predictions <- mod3%>% 
  predict(Avg4_W)

# Predictions with 95% CI
predictions <- mod3 %>% 
  predict(Avg4_W, interval = "confidence")

compare <- data.frame(actual = Avg4_W$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_W$avg_demand_mgd)
targ<-Avg4_W$avg_demand_mgd
print("Winter is coming (House Stark)")
mmetric(targ,predictions,metrics_list)
```


## KSVM Model

```{r}
set.seed(6496)
mod4 <- ksvm(avg_demand_mgd ~ ., data = train, kernal="polydot", C=10)
```

rbfdot Radial Basis kernel "Gaussian"

polydot Polynomial kernel

vanilladot Linear kernel

tanhdot Hyperbolic tangent kernel

laplacedot Laplacian kernel

besseldot Bessel kernel

anovadot ANOVA RBF kernel

splinedot Spline kernel

stringdot String kernel


The cost parameter penalizes large residuals. So a larger cost will result in a more flexible model with fewer misclassifications. In effect the cost parameter allows you to adjust the bias/variance trade-off. The greater the cost parameter, the more variance in the model and the less bias. Default is 1.. 


```{r}
# Train
trainpred <- mod4%>% 
  predict(train)

# Predictions with 95% CI
trainpredCI <- mod4 %>% 
  predict(train, interval = "confidence")

compare <- data.frame(actual = train$avg_demand_mgd,
                      predicted = trainpred)

error <- RMSE(trainpred,train$avg_demand_mgd)
ttarg<-train$avg_demand_mgd
print("Train")
mmetric(ttarg,trainpred,metrics_list)

print("_____________________________________")

# Test
predictions <- mod4%>% 
  predict(test)

# Predictions with 95% CI
testpredCI <- mod4 %>% 
  predict(test, interval = "confidence")

compare <- data.frame(actual = test$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,test$avg_demand_mgd)
targ<-test$avg_demand_mgd
print("Test")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# 2022
predictions <- mod4%>% 
  predict(Avg4_2022)

# Predictions with 95% CI
predictions <- mod4 %>% 
  predict(Avg4_2022, interval = "confidence")

compare <- data.frame(actual = Avg4_2022$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_2022$avg_demand_mgd)
targ<-Avg4_2022$avg_demand_mgd
print("2022")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# Spring
predictions <- mod4%>% 
  predict(Avg4_Sp)

# Predictions with 95% CI
predictions <- mod4 %>% 
  predict(Avg4_SP, interval = "confidence")

compare <- data.frame(actual = Avg4_Sp$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_Sp$avg_demand_mgd)
targ<-Avg4_Sp$avg_demand_mgd
print("Spring")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# Summer
predictions <- mod4%>% 
  predict(Avg4_Su)

# Predictions with 95% CI
predictions <- mod4 %>% 
  predict(Avg4_Su, interval = "confidence")

compare <- data.frame(actual = Avg4_Su$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_Su$avg_demand_mgd)
targ<-Avg4_Su$avg_demand_mgd
print("Summer")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# Fall
predictions <- mod4%>% 
  predict(Avg4_F)

# Predictions with 95% CI
predictions <- mod4 %>% 
  predict(Avg4_F, interval = "confidence")

compare <- data.frame(actual = Avg4_F$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_F$avg_demand_mgd)
targ<-Avg4_F$avg_demand_mgd
print("Fall")
mmetric(targ,predictions,metrics_list)

print("_____________________________________")

# Winter
predictions <- mod4%>% 
  predict(Avg4_W)

# Predictions with 95% CI
predictions <- mod4 %>% 
  predict(Avg4_W, interval = "confidence")

compare <- data.frame(actual = Avg4_W$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,Avg4_W$avg_demand_mgd)
targ<-Avg4_W$avg_demand_mgd
print("Winter is coming (House Stark)")
mmetric(targ,predictions,metrics_list)
```


> The best perofrming model is mod3


# 10 Fold Cross Validation

```{r}
df <- Avg4
target <- 11
seedVal <- 6496
metrics_list = c("R2","MAE","MAPE","RMSE")

cv_function <- function(df, target, nFolds, seedVal, metrics_list)
{
# create folds using the assigned values

set.seed(seedVal)
folds = createFolds(df[,target],nFolds)

# The lapply loop

cv_results <- lapply(folds, function(x)
{ 
# data preparation:

  test_target <- df[x,target]
  test_input <- df[x,-target]
  
  train_target <- df[-x,target]
  train_input <- df[-x,-target]

  
   model <- mod3 
  pred <- predict(model, test_input)
  return(mmetric(test_target,pred,metrics_list))
})

cv_results_m <- as.matrix(as.data.frame(cv_results))
cv_mean<- as.matrix(rowMeans(cv_results_m))
cv_sd <- as.matrix(rowSds(cv_results_m))
colnames(cv_mean) <- "Mean"
colnames(cv_sd) <- "Sd"
cv_all <- cbind(cv_results_m, cv_mean, cv_sd)
kable(t(cv_all),digits=2)
}
```

```{r}
cv_function(Avg4, target, 10, seedVal, metrics_list)
```

# 3 Fold Cross Validation Winter

```{r}
df <- Avg4_W
target <- 11
seedVal <- 6496
metrics_list = c("R2","MAE","MAPE","RMSE")
nFolds = 3

cv_function <- function(df, target, nFolds, seedVal, metrics_list)
{
# create folds using the assigned values

set.seed(seedVal)
folds = createFolds(df[,target],nFolds)

# The lapply loop

cv_results <- lapply(folds, function(x)
{ 
# data preparation:

  test_target <- df[x,target]
  test_input <- df[x,-target]
  
  train_target <- df[-x,target]
  train_input <- df[-x,-target]

  
   model <- mod3 
  pred <- predict(model, test_input)
  return(mmetric(test_target,pred,metrics_list))
})

cv_results_m <- as.matrix(as.data.frame(cv_results))
cv_mean<- as.matrix(rowMeans(cv_results_m))
cv_sd <- as.matrix(rowSds(cv_results_m))
colnames(cv_mean) <- "Mean"
colnames(cv_sd) <- "Sd"
cv_all <- cbind(cv_results_m, cv_mean, cv_sd)
kable(t(cv_all),digits=2)
}
```


```{r}
cv_function(Avg4, target, nFolds, seedVal, metrics_list)
```

