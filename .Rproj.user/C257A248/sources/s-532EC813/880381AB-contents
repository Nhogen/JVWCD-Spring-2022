---
title: "Model"
author: "JVWCD Capstone Group"
date: "3/29/2022"
output: 
  html_document:
    highlight: breezedark
    number_sections: yes
    toc: yes
    fig_width: 15
    fig_height: 10
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Read Data

## Packages

```{r echo=T, results='hide', message=F, warning=F}
list.of.packages <- c("tidyverse",
                      "lubridate",
                      "chron",
                      "knitr",
                      "corrplot",
                      "caret",
                      "scales",
                      "gridExtra",
                      "useful",
                      "ISOweek",
                      "kableExtra",
                      "matrixStats",
                      "rminer",
                      "mltools")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

library(tidyverse)
library(lubridate)
library(chron)
library(knitr)
library(corrplot)
library(caret)
library(scales)
library(gridExtra)
library(useful)
library(ISOweek)
library(kableExtra)
library(matrixStats)
library(rminer)
library(mltools)
```

## Read CSV files and pre process

### Weather Data

```{r}
wa <- read.csv("new_weather_slc_airport.csv")%>%
  mutate(season = ifelse(CalendarMonth %in% c('3','4','5'), 'Spring',
                         ifelse(CalendarMonth %in% c('6','7','8'), 'Summer',
                                ifelse(CalendarMonth %in% c('9','10','11'), 'Fall',
                                       ifelse(CalendarMonth %in% c('12','1','2'), 'Winter','0')))),
         #RainDays = factor(RainDays),
         date = as.Date(WeatherDate,format="%m/%d/%Y"),
         RainDays = ifelse(Precipitation < 0.05, 0 , RainDays),
         Precipitation = ifelse(Precipitation < 0.05, 0 , Precipitation))%>%
  filter(CalendarYear>=2020)
```

### System Demand Data

```{r}
sd <- read.csv("new_daily_demand.csv")%>%
  rename('avg_demand_cfs' = 'Avg.Daily.Demand..cfs.',
         'avg_demand_af' = 'Avg.Daily.Demand..af.',
         'avg_demand_mgd' = 'Avg.Daily.Demand..mgd.',
         'max_demand_cfs' = 'Max.Daily.Demand..cfs.',
         'max_demand_af' = 'Max.Daily.Demand..af.',
         'max_demand_mgd' = 'Max.Daily.Demand..mgd.',
         'min_demand_cfs' = 'Min.Daily.Demand..cfs.',
         'min_demand_af' = 'Min.Daily.Demand..af.',
         'min_demand_mgd' = 'Max.Daily.Demand..mgd..1')%>%#Clifton said this is a min
  mutate(date = as.Date(ReadDate,format="%m/%d/%Y"))

```

> CFS (cubic feet per second) – This is a measurement of flow at a given point. It represents how many cubic feet pass a point in each second. For example, if you have an average of 30 cfs at 1 p.m., that means that during that hour, an average of 30 cubic feet was passing the point each second.


> AF (acre feet) – This is a measurement of volume. One acre foot of water would cover an entire acre at a depth of one foot. It doesn’t have a time associated with it, so it isn’t a flow. For example, if you had 30 af at 1 p.m. that means a total of 30 acre-feet passed through that point during that hour. When converting a flow to a volume we must include a time measurement in the volume. So, an hourly acre-foot volume could be converted to cfs by converting it to a flow like acre-feet per hour.


> MGD (million gallons per day) – This is also a flow measurement and is like cfs in that it represents an amount of water flowing past a point during a given time.

> I think the most important measurement for our purposes is MGD since that’s the unit of measurement the Operations department uses. I’m checking up on that, though, and will let you know for sure. Also, it’s entirely possible that I’m not answering your question, so please feel free to clarify whatever you need. -Clifton

### Join Weather and Demand Data


```{r}
wd <- merge(wa,sd,by="date")
```

### Select MGD Average as Target Variable

Taking out the demand that is not average MGD. Since the other data points are not demand we couldn't use them for a model.

```{r}
mgd_avg <- wd%>%
  select(-avg_demand_cfs,
         -avg_demand_af,
         #-avg_demand_mgd, ## Target Variable
         -max_demand_cfs,
         -max_demand_af,
         -max_demand_mgd,
         -min_demand_cfs,
         -min_demand_af,
         -min_demand_mgd)%>%
  select(-WeatherDate,-ReadDate)
  

```

> If we want to try to predict other vairables we can just uncomment avg_demand_mgd and comment out the one we want to predict for. Not sure if we want to do that though?

# Add custom functions

## Create function that will average 3 previous rows

```{r}
moving_avg_3_rows <- function(x){
  (lag(x,4) + lag(x,3) + lag(x,2) + lag(x,1))/4
}
#ChangeDay
#moving_avg_3_rows <- function(x){
#  (lag(x,14) + lag(x,13) + lag(x,12) + lag(x,11) + lag(x,10) + lag(x,9) + lag(x,8) + lag(x,7) + lag(x,6) + lag(x,5) + lag(x,4) + lag(x,3) + lag(x,2) + lag(x,1))/14
#}
```

## Create function to calculate R^2

```{r}
rsq <- function (x, y) cor(x, y) ^ 2

```

## Add Rain Week Variable

```{r}
rainwk <- mgd_avg %>%
  mutate(Week_no = format(date, "%U"))%>%
  group_by(Week_no)%>%
  summarize(RainWeek = as.factor(ifelse(sum(RainDays)>0,1,0)))

mgd_avg <- mgd_avg %>%
  mutate(Week_no = as.factor(format(date, "%U")),
         RainDays = as.factor(RainDays),
         season = as.factor(season))

mgd_avg <- dplyr::left_join(mgd_avg,rainwk,by="Week_no")

mgd_avg <- mgd_avg%>% select(-Week_no)




glimpse(mgd_avg)
summary(mgd_avg)
```

# Create 3 Datasets to try different models

## Move Everything to PrevDay

```{r}
#Change everything to Prevday
PrevDayAll = shift.column(mgd_avg,columns =c('TemperatureMean',
                                             'TemperatureMax',
                                             'TemperatureMin',
                                             'Precipitation',
                                             'CoolingDegreeDays',
                                             'SnowDepth',
                                             'SnowFall',
                                             'RainDays'),len = 1L,up=TRUE)

#Remove unshifted columns
PrevDayAll = PrevDayAll %>% 
  select(-one_of('TemperatureMean',
                 'TemperatureMax',
                 'TemperatureMin',
                 'Precipitation',
                 'CoolingDegreeDays',
                 'SnowDepth',
                 'SnowFall',
                 'RainDays'))

#Rename Columns
PrevDayAll = PrevDayAll %>% 
  rename(PrevDayMeanTemp = TemperatureMean.Shifted,
         PrevDayMaxTemp = TemperatureMax.Shifted,
         PrevDayMinTemp = TemperatureMin.Shifted,
         PrevDayRain = Precipitation.Shifted,
         PrevDayCoolingDegDays = CoolingDegreeDays.Shifted,
         PrevDaySnowDepth = SnowDepth.Shifted,
         PrevDaySnowFall = SnowFall.Shifted,
         PrevDayRainDay = RainDays.Shifted,)

glimpse(PrevDayAll)
summary(PrevDayAll)
```


## Add 3 day moving average columns

```{r}
Avg3 = mgd_avg %>% 
  mutate(Precip3Day = ifelse(is.na(moving_avg_3_rows(Precipitation)),Precipitation,
                           moving_avg_3_rows(Precipitation)),
         Tempmean3Day = ifelse(is.na(moving_avg_3_rows(TemperatureMean)),TemperatureMean,
                           moving_avg_3_rows(TemperatureMean)))%>% 
  select(-one_of('TemperatureMean',#Remove un averaged columns
                 'Precipitation',
                 'SnowDepth'))
```



```{r}
glimpse(Avg3)
summary(Avg3)
```
> Here we took the 3 day average of some of the most interesting variables per our EDA. We used 0.05 as our benchmark for statistically significant. 

##  Variable choice methodology

Precipitation:

Precipitation had a P-Value of 0.09 witch means that we cannot reject the null hypotheses.

Precipitation was negatively correlated with demand. It's correlation score was -0.0349699 with 1 being 100% positive correlation and -1 being 100% negative correlation. 

However despite this information we decided that it was still a useful predictor because it is very intuitive what rainfall does to water demand.It is very intuitive that when it rains people water less. We think it'd due to the frequency of rain that the statistics show it as not very significant.

Still we wanted to try and extract the significance of this variable so we wanted to the the average of the last 3 days and see if that becomes significant.

Temperature:

For temperature mean, r reports p value as < 2.2e-16, which is shorthand for 0.00000000000000022. With our alpha of 0.05, we can confidently reject the null hypothesis.

It's correlation to our tarter variable was positive with a score of 0.5495006. Because of this information we thought the average of the last 3 days could help improve our model.

## Remove Calendar Variables from Datasets to see how model performance if affected.

```{r}
mgd_avg <- mgd_avg%>%
  select(-date,
         -CalendarYear,
         -CalendarMonth,
         -CalendarDay)%>%
  mutate(season = as.factor(season))
  

Avg3 <- Avg3%>%
  select(-date,
         -CalendarYear,
         -CalendarMonth,
         -CalendarDay)%>%
  mutate(season = as.factor(season))

PrevDayAll <- PrevDayAll%>%
  select(-date,
         -CalendarYear,
         -CalendarMonth,
         -CalendarDay)%>%
  mutate(season = as.factor(season))

```

> I wanted to try removing these variables because it felt more consistant with our goal of predicting water demand based on weather data. 

> I did try factoring a week number variable and this made the model overfit with a very high R^2 score on both train and test. I beleive this is because we only had one year of data.

> I found that removing these varibles actually improved model performance.


# Corrplots

```{r}
wdn <- Avg3%>%
  select_if(is.numeric)
```

```{r}
#an attempt to manually look at the most important numeric vars
cwdn <- cor(wdn, use="pairwise.complete.obs")
cwdn1 <- data.frame(sort(cwdn[,'avg_demand_mgd'], decreasing = TRUE))
```

```{r}
cwdn1%>%
  rename(Correlation = "sort.cwdn....avg_demand_mgd....decreasing...TRUE.")#%>%
  #kable()

```

```{r}
# Correlation of numeric variables with their numbers and shap/color relation to sale price
corrplot(cwdn, tl.col="black", tl.pos = "lt", tl.cex = 0.7,cl.cex = .7, number.cex=.7, method = "number", order="AOE")
```

# Split all datasets into Train and test

```{r}
set.seed(6496)

#mgd_avg

ti <- createDataPartition(mgd_avg$avg_demand_mgd, p=0.7,
                         list = FALSE)

train <- mgd_avg[ti,]
test <- mgd_avg[-ti,]


#Avg3

ti1 <- createDataPartition(Avg3$avg_demand_mgd, p=0.7,
                         list = FALSE)

train_Avg3 <- Avg3[ti1,]
test_Avg3 <- Avg3[-ti1,]

#PrevDayAll

ti2 <- createDataPartition(PrevDayAll$avg_demand_mgd, p=0.7,
                         list = FALSE)

train_PrevDayAll <- PrevDayAll[ti2,]
test_PrevDayAll <- PrevDayAll[-ti2,]


metrics_list = c("R2","MAE","MAPE","RMSE")

```



# Models

## Model with our standard transformations

```{r}
mod <- lm(avg_demand_mgd ~., data=train)
summary(mod)
```

> It is clear from this model that Precip3Day was a much more useful predictor than perciprition alone because it was more statistcally significant and had a more dramatic coeficient. This makes sense because 261 weeks in the year had rainfall so it seems as though it would have a large impact.


## Model with Average 3 days

```{r}
mod_Avg3 <- lm(avg_demand_mgd ~., data=train_Avg3)

summary(mod_Avg3)
```

## Model with all weather data looking at yesterday

```{r}
mod_PrevDayAll <- lm(avg_demand_mgd ~., data=train_PrevDayAll)
summary(mod_PrevDayAll)
```


# Model Selection

## Performance Metrics

R2 : Tells us that the predictor variables in the model are able to explain x% of the variation in target variable.

MAE: Is to subtract our predicted value and actual value at each time point to obtain the absolute value, and then average it out.

RMSE: tells us the average deviation between the predicted demand made by the model and the actual demand value.

MAPE: returns error as a percentage, making it easy to understand:
MAPE	Interpretation
' < 10 %	Very good
' 10 % - 20 %	Good
' 20 % - 50 %	OK
' > 50 %	Not good

```{r}
set.seed(6496)

#mod
trainpred <- mod%>% 
  predict(train)

compare <- data.frame(actual = train$avg_demand_mgd,
                      predicted = trainpred)

error <- RMSE(trainpred,train$avg_demand_mgd)
ttarg<-train$avg_demand_mgd
mmetric(ttarg,trainpred,metrics_list)

#mod_Avg3
trainpred <- mod_Avg3 %>% 
  predict(train_Avg3)

compare <- data.frame(actual = train_Avg3$avg_demand_mgd,
                      predicted = trainpred)

error <- RMSE(trainpred,train_Avg3$avg_demand_mgd)
ttarg<-train_Avg3$avg_demand_mgd
mmetric(ttarg,trainpred,metrics_list)

#mod_PrevDayAll
trainpred <- mod_PrevDayAll%>% 
  predict(train_PrevDayAll)

compare <- data.frame(actual = train_PrevDayAll$avg_demand_mgd,
                      predicted = trainpred)

error <- RMSE(trainpred,train_PrevDayAll$avg_demand_mgd)
ttarg<-train_PrevDayAll$avg_demand_mgd
mmetric(ttarg,trainpred,metrics_list)
```

> R2 : mod_Avg3 wins this one as you want the higest possible value
> MAE : 



## Test mod

```{r}
predictions <- mod %>% 
  predict(test)

compare <- data.frame(actual = test$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,test$avg_demand_mgd)
targ<-test$avg_demand_mgd
mmetric(targ,predictions,metrics_list)


```



## Test mod_Avg3

```{r}
predictions <- mod_Avg3 %>% 
  predict(test_Avg3)

compare <- data.frame(actual = test_Avg3$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,test_Avg3$avg_demand_mgd)
targ<-test_Avg3$avg_demand_mgd
mmetric(targ,predictions,metrics_list)


```


## Test mod_PrevDayAll

```{r}
predictions <- mod_PrevDayAll %>% 
  predict(test_PrevDayAll)

compare <- data.frame(actual = test_PrevDayAll$avg_demand_mgd,
                      predicted = predictions)

error <- RMSE(predictions,test_PrevDayAll$avg_demand_mgd)
targ<-test_PrevDayAll$avg_demand_mgd
mmetric(targ,predictions,metrics_list)


```

> To summarize the model with the average of the last 3 days for those 3 variables performed the best of both the train and the test data.


```{r}
#rsq(compare$actual,compare$predicted)

#Value with 1 day is 0.8873063
#Value with 2 day is 0.8950486
#Value with 3 day is 0.9019893
#Value with 4 day is 0.9035643
#Value with 5 day is 0.9005719
#Value with 6 day is 0.8981314
#Value with 7 day is 0.9017859
#Value with 8 day is 0.9048090
#Value with 9 day is 0.9044366
#Value with 10 day is 0.9031666
#Value with 11 day is 0.9029562
#Value with 12 day is 0.9010406
#Value with 13 day is 0.8987119
#Value with 14 day is 0.8988761

```











